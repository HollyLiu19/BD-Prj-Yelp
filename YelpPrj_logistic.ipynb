{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Final Project Yelp \n",
    "## Group Members: Haoning Liu, Jiaqi Chen, Mengqi Liu, Xiaolu Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-69-183.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BD4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f75183b7780>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"BD4\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one of four data files 'review' from local\n",
    "review = pd.read_csv(\"/Users/lhnzm/yelp_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comma, quotation mark, and changing line character from text column\n",
    "review['text'] = review['text'].str.replace(',', '')\n",
    "review['text'] = review['text'].str.replace('\"', '')\n",
    "review['text'] = review['text'].str.replace('\\r\\n', '')\n",
    "review['text'] = review['text'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out separating with comma and upload to S3 bucket\n",
    "review.to_csv('review1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV files from S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/review1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=review.drop('_c0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check unique values for each column and whether data has been read in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         business_id|\n",
      "+--------------------+\n",
      "|f4mh1Y0rnvbJRfQ3j...|\n",
      "|cKwg6HFaLYXl7Ar0r...|\n",
      "|jcpgiXF0PCyS9hrvq...|\n",
      "|R_M4P9XetEM-aLE7e...|\n",
      "|DEBqmgxv2yhJ93LqG...|\n",
      "|Cml4Yt5cTx64cOMan...|\n",
      "|bo3SQVtErnMOqO6lk...|\n",
      "|Cl-xl1vTUwHeaGgBx...|\n",
      "|oIEmXWLtoh5blz-iw...|\n",
      "|Op2IR4FffXZ5KXYFn...|\n",
      "|yB5FMuc9Y3oyhsOmu...|\n",
      "|cEqOh78v1g1RCWHyu...|\n",
      "|lt8IW9Bpy9GMeKGxy...|\n",
      "|uC3qwaxsOkdJzpOc0...|\n",
      "|686oeWNsbc-aczplC...|\n",
      "|gPuxh3HNvoVt8aWVW...|\n",
      "|mA27CG2U3ytmkxIGV...|\n",
      "|x6qH9HXhzuKM03jcZ...|\n",
      "|74LU6K2ro5AQXKT0J...|\n",
      "|TdefcbsFAj6WXHwlG...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('business_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.select('business_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|stars|\n",
      "+-----+\n",
      "| null|\n",
      "|    1|\n",
      "|    3|\n",
      "|    5|\n",
      "|    4|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('stars').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             user_id|\n",
      "+--------------------+\n",
      "|rs3pq6wRmaSIADCIn...|\n",
      "|xS6kmkMXp0PRrFwkS...|\n",
      "|aNOSjqQFsrfcgmFtO...|\n",
      "|-9da1xk7zgnnfO1uT...|\n",
      "|PLjruA-EMskWfirBU...|\n",
      "|O-frog8VhICKAT0gr...|\n",
      "|7o473jeLWW-zgKN-Q...|\n",
      "|L1XxGWFJ3S7xBQCT8...|\n",
      "|D2ljL5ejuqpa4f8fn...|\n",
      "|CzkWUMIYDxUSetfCR...|\n",
      "|5avk-VCo_6Bx65ct1...|\n",
      "|oKWVVqPWVzq5s6nS4...|\n",
      "|e5kxYMksMVWApEJdO...|\n",
      "|f-6oae7TltlfJicUi...|\n",
      "|NL9jmu5jSkCdMM-i9...|\n",
      "|z6gjzFENiQf-K3lPy...|\n",
      "|Al2g2P9gt057Julh1...|\n",
      "|midS4e50ZmuOeGyNm...|\n",
      "|yTr8nlIjQCJWc0ZIC...|\n",
      "|yb0AdKzhYwQIlt47r...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('user_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|useful|\n",
      "+------+\n",
      "|   148|\n",
      "|    31|\n",
      "|    85|\n",
      "|   251|\n",
      "|   808|\n",
      "|   137|\n",
      "|    65|\n",
      "|    53|\n",
      "|   255|\n",
      "|   970|\n",
      "|   133|\n",
      "|    78|\n",
      "|   362|\n",
      "|   108|\n",
      "|   155|\n",
      "|    34|\n",
      "|   193|\n",
      "|   101|\n",
      "|   126|\n",
      "|   115|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('useful').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|funny|\n",
      "+-----+\n",
      "|  148|\n",
      "|   31|\n",
      "|   85|\n",
      "|  137|\n",
      "|   65|\n",
      "|   53|\n",
      "|  970|\n",
      "|  133|\n",
      "|   78|\n",
      "|  322|\n",
      "|  108|\n",
      "|  155|\n",
      "|   34|\n",
      "|  101|\n",
      "|  115|\n",
      "|   81|\n",
      "|   28|\n",
      "|  183|\n",
      "|  412|\n",
      "|   76|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('funny').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               date|\n",
      "+-------------------+\n",
      "|2010-10-05 19:12:35|\n",
      "|2016-02-11 22:26:21|\n",
      "|2015-01-18 16:00:39|\n",
      "|2012-11-06 05:23:38|\n",
      "|2013-11-14 04:08:35|\n",
      "|2015-06-21 02:01:34|\n",
      "|2018-09-25 05:26:16|\n",
      "|2015-04-01 17:43:03|\n",
      "|2014-04-19 12:06:45|\n",
      "|2018-09-25 03:51:25|\n",
      "|2014-02-23 21:39:30|\n",
      "|2016-08-03 23:31:26|\n",
      "|2016-07-25 07:00:01|\n",
      "|2018-04-04 03:02:29|\n",
      "|2017-08-28 19:16:03|\n",
      "|2017-10-11 02:23:26|\n",
      "|2016-06-22 21:16:05|\n",
      "|2008-08-18 22:32:45|\n",
      "|2007-12-09 15:16:21|\n",
      "|2015-05-12 16:16:59|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('date').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review.drop('review_id','text','date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.withColumnRenamed('stars', 'stars_business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- is_open: integer (nullable = true)\n",
      " |-- attributes.GoodForKids: string (nullable = true)\n",
      " |-- attributes.RestaurantsReservations: string (nullable = true)\n",
      " |-- attributes.GoodForMeal: string (nullable = true)\n",
      " |-- attributes.BusinessParking: string (nullable = true)\n",
      " |-- attributes.Caters: string (nullable = true)\n",
      " |-- attributes.NoiseLevel: string (nullable = true)\n",
      " |-- attributes.RestaurantsTableService: string (nullable = true)\n",
      " |-- attributes.RestaurantsTakeOut: string (nullable = true)\n",
      " |-- attributes.RestaurantsPriceRange2: string (nullable = true)\n",
      " |-- attributes.OutdoorSeating: string (nullable = true)\n",
      " |-- attributes.BikeParking: string (nullable = true)\n",
      " |-- attributes.Ambience: string (nullable = true)\n",
      " |-- attributes.HasTV: string (nullable = true)\n",
      " |-- attributes.WiFi: string (nullable = true)\n",
      " |-- attributes.Alcohol: string (nullable = true)\n",
      " |-- attributes.RestaurantsAttire: string (nullable = true)\n",
      " |-- attributes.RestaurantsGoodForGroups: string (nullable = true)\n",
      " |-- attributes.RestaurantsDelivery: string (nullable = true)\n",
      " |-- attributes.BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |-- attributes.BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |-- attributes.ByAppointmentOnly: string (nullable = true)\n",
      " |-- attributes.AcceptsInsurance: string (nullable = true)\n",
      " |-- attributes.Music: string (nullable = true)\n",
      " |-- attributes.GoodForDancing: string (nullable = true)\n",
      " |-- attributes.CoatCheck: string (nullable = true)\n",
      " |-- attributes.HappyHour: string (nullable = true)\n",
      " |-- attributes.BestNights: string (nullable = true)\n",
      " |-- attributes.WheelchairAccessible: string (nullable = true)\n",
      " |-- attributes.DogsAllowed: string (nullable = true)\n",
      " |-- attributes.BYOBCorkage: string (nullable = true)\n",
      " |-- attributes.DriveThru: string (nullable = true)\n",
      " |-- attributes.Smoking: string (nullable = true)\n",
      " |-- attributes.AgesAllowed: string (nullable = true)\n",
      " |-- attributes.HairSpecializesIn: string (nullable = true)\n",
      " |-- attributes.Corkage: string (nullable = true)\n",
      " |-- attributes.BYOB: string (nullable = true)\n",
      " |-- attributes.DietaryRestrictions: string (nullable = true)\n",
      " |-- attributes.Open24Hours: string (nullable = true)\n",
      " |-- attributes.RestaurantsCounterService: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- hours.Monday: string (nullable = true)\n",
      " |-- hours.Tuesday: string (nullable = true)\n",
      " |-- hours.Wednesday: string (nullable = true)\n",
      " |-- hours.Thursday: string (nullable = true)\n",
      " |-- hours.Friday: string (nullable = true)\n",
      " |-- hours.Saturday: string (nullable = true)\n",
      " |-- hours.Sunday: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.select('business_id','state','city','latitude','longitude',\"stars_business\",\"review_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_tip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = tip.select('user_id','business_id','compliment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.withColumnRenamed('useful','useful_user')\\\n",
    ".withColumnRenamed('funny','funny_user')\\\n",
    ".withColumnRenamed('cool','cool_user')\\\n",
    ".withColumnRenamed('review_count','review_count_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.select('user_id','average_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data by business ID and user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined1 = review.join(business, on='business_id', how='left_outer')\n",
    "#combined1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined2 = combined1.join(user, on='user_id', how='left_outer')\n",
    "#combined2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print schema of combined data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined = combined2.join(tip, on=['business_id', 'user_id',], how='left_outer')\n",
    "combined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555074"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check null value in stars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "| null|    134|\n",
      "|    1| 371228|\n",
      "|    3| 281425|\n",
      "|    5|1131301|\n",
      "|    4| 567828|\n",
      "|    2| 203158|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.groupby(combined.stars).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with nulls in stars column because the number of nulls is only 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.filter(combined.stars.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert stars no more than 3 to 0 while stars more than 3 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = combined.withColumn('stars',when(combined.stars <= 3, '0').otherwise('1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count boolean values in stars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|    0| 855811|\n",
      "|    1|1699129|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(df.stars).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pipeline and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the string fields to numeric ones\n",
    "stringIndexer_label = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep')\n",
    "\n",
    "stringIndexer_city = StringIndexer(inputCol=\"city\", outputCol=\"city_SI\",handleInvalid='keep')\n",
    "stringIndexer_state = StringIndexer(inputCol=\"state\", outputCol=\"state_SI\",handleInvalid='keep')\n",
    "stringIndexer_compliment_count = StringIndexer(inputCol=\"compliment_count\", outputCol=\"compliment_count_SI\",handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at values for one of the re-encoded columns using fit method\n",
    "si_label_fit = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_label_fit.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_6326843d9a00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a feature vector by combining all features together\n",
    "\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"state_SI\", \n",
    "               \"city_SI\",\n",
    "               \"compliment_count_SI\", \n",
    "               \"useful\",\n",
    "               \"funny\",\n",
    "               \"cool\",\n",
    "               \"latitude\",\n",
    "               \"longitude\",\n",
    "               \"stars_business\",\n",
    "               \"review_count\",\n",
    "               \"average_stars\"], \n",
    "    outputCol=\"features\",\n",
    "    handleInvalid='keep')\n",
    "vectorAssembler_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index labels back to original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", \n",
    "                               outputCol=\"predictedLabel\", \n",
    "                               labels=stringIndexer_label.fit(df).labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector by combining all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[stringIndexer_label,\n",
    "                               stringIndexer_state,\n",
    "                               stringIndexer_city,\n",
    "                               stringIndexer_compliment_count,\n",
    "                               vectorAssembler_features,\n",
    "                               lr,labelConverter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 splits of combined data (train, test) by using the randomSplit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 2044211\n",
      "Number of testing records : 510729\n"
     ]
    }
   ],
   "source": [
    "splitted_data = df.randomSplit([0.8, 0.2])\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check schema of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: string (nullable = false)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = pipeline_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do predictions with testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lr.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the curve (AUC) for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.818937\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluatorLR = BinaryClassificationEvaluator()\n",
    "accuracy = evaluatorLR.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`predictions`' given input columns: [city, business_id, stars, state_SI, features, average_stars, prediction, cool, useful, rawPrediction, user_id, review_count, city_SI, predictedLabel, probability, stars_business, label, compliment_count_SI, state, compliment_count, funny, latitude, longitude];;\\n'Project [label#1030, 'predictions]\\n+- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, prediction#1166, if (isnull(cast(prediction#1166 as double))) null else UDF(cast(prediction#1166 as double)) AS predictedLabel#1211]\\n   +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, UDF(rawPrediction#1123) AS prediction#1166]\\n      +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, UDF(rawPrediction#1123) AS probability#1144]\\n         +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, UDF(features#1103) AS rawPrediction#1123]\\n            +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, UDF(named_struct(state_SI, state_SI#1046, city_SI, city_SI#1063, compliment_count_SI, compliment_count_SI#1081, useful_double_VectorAssembler_6326843d9a00, cast(useful#15 as double), funny_double_VectorAssembler_6326843d9a00, cast(funny#16 as double), cool_double_VectorAssembler_6326843d9a00, cast(cool#17 as double), latitude, latitude#61, longitude, longitude#62, stars_business, stars_business#171, review_count, review_count#64, average_stars, average_stars#280)) AS features#1103]\\n               +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, UDF(cast(compliment_count#251 as string)) AS compliment_count_SI#1081]\\n                  +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, UDF(cast(city#58 as string)) AS city_SI#1063]\\n                     +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, UDF(cast(state#59 as string)) AS state_SI#1046]\\n                        +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, UDF(cast(stars#447 as string)) AS label#1030]\\n                           +- Sample 0.8, 1.0, false, 4135539898498538077\\n                              +- Sort [business_id#13 ASC NULLS FIRST, user_id#12 ASC NULLS FIRST, stars#447 ASC NULLS FIRST, useful#15 ASC NULLS FIRST, funny#16 ASC NULLS FIRST, cool#17 ASC NULLS FIRST, state#59 ASC NULLS FIRST, city#58 ASC NULLS FIRST, latitude#61 ASC NULLS FIRST, longitude#62 ASC NULLS FIRST, stars_business#171 ASC NULLS FIRST, review_count#64 ASC NULLS FIRST, average_stars#280 ASC NULLS FIRST, compliment_count#251 ASC NULLS FIRST], false\\n                                 +- Project [business_id#13, user_id#12, CASE WHEN (stars#14 <= 3) THEN 0 ELSE 1 END AS stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\\n                                    +- Filter isnotnull(stars#14)\\n                                       +- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\\n                                          +- Join LeftOuter, ((business_id#13 = business_id#248) && (user_id#12 = user_id#247))\\n                                             :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280]\\n                                             :  +- Join LeftOuter, (user_id#12 = user_id#270)\\n                                             :     :- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\\n                                             :     :  +- Join LeftOuter, (business_id#13 = business_id#55)\\n                                             :     :     :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17]\\n                                             :     :     :  +- Project [review_id#11, user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, text#18, date#19]\\n                                             :     :     :     +- Relation[_c0#10,review_id#11,user_id#12,business_id#13,stars#14,useful#15,funny#16,cool#17,text#18,date#19] csv\\n                                             :     :     +- Project [business_id#55, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\\n                                             :     :        +- Project [business_id#55, name#56, address#57, city#58, state#59, postal_code#60, latitude#61, longitude#62, stars#63 AS stars_business#171, review_count#64, is_open#65, attributes.GoodForKids#66, attributes.RestaurantsReservations#67, attributes.GoodForMeal#68, attributes.BusinessParking#69, attributes.Caters#70, attributes.NoiseLevel#71, attributes.RestaurantsTableService#72, attributes.RestaurantsTakeOut#73, attributes.RestaurantsPriceRange2#74, attributes.OutdoorSeating#75, attributes.BikeParking#76, attributes.Ambience#77, attributes.HasTV#78, ... 34 more fields]\\n                                             :     :           +- Relation[business_id#55,name#56,address#57,city#58,state#59,postal_code#60,latitude#61,longitude#62,stars#63,review_count#64,is_open#65,attributes.GoodForKids#66,attributes.RestaurantsReservations#67,attributes.GoodForMeal#68,attributes.BusinessParking#69,attributes.Caters#70,attributes.NoiseLevel#71,attributes.RestaurantsTableService#72,attributes.RestaurantsTakeOut#73,attributes.RestaurantsPriceRange2#74,attributes.OutdoorSeating#75,attributes.BikeParking#76,attributes.Ambience#77,attributes.HasTV#78,... 34 more fields] csv\\n                                             :     +- Project [user_id#270, average_stars#280]\\n                                             :        +- Project [user_id#270, name#271, review_count#272 AS review_count_user#383, yelping_since#273, useful_user#314, funny_user#337, cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :           +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny_user#337, cool#276 AS cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :              +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny#275 AS funny_user#337, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :                 +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful#274 AS useful_user#314, funny#275, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :                    +- Relation[user_id#270,name#271,review_count#272,yelping_since#273,useful#274,funny#275,cool#276,elite#277,friends#278,fans#279,average_stars#280,compliment_hot#281,compliment_more#282,compliment_profile#283,compliment_cute#284,compliment_list#285,compliment_note#286,compliment_plain#287,compliment_cool#288,compliment_funny#289,compliment_writer#290,compliment_photos#291] csv\\n                                             +- Project [user_id#247, business_id#248, compliment_count#251]\\n                                                +- Relation[user_id#247,business_id#248,text#249,date#250,compliment_count#251] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o609.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`predictions`' given input columns: [city, business_id, stars, state_SI, features, average_stars, prediction, cool, useful, rawPrediction, user_id, review_count, city_SI, predictedLabel, probability, stars_business, label, compliment_count_SI, state, compliment_count, funny, latitude, longitude];;\n'Project [label#1030, 'predictions]\n+- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, prediction#1166, if (isnull(cast(prediction#1166 as double))) null else UDF(cast(prediction#1166 as double)) AS predictedLabel#1211]\n   +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, UDF(rawPrediction#1123) AS prediction#1166]\n      +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, UDF(rawPrediction#1123) AS probability#1144]\n         +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, UDF(features#1103) AS rawPrediction#1123]\n            +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, UDF(named_struct(state_SI, state_SI#1046, city_SI, city_SI#1063, compliment_count_SI, compliment_count_SI#1081, useful_double_VectorAssembler_6326843d9a00, cast(useful#15 as double), funny_double_VectorAssembler_6326843d9a00, cast(funny#16 as double), cool_double_VectorAssembler_6326843d9a00, cast(cool#17 as double), latitude, latitude#61, longitude, longitude#62, stars_business, stars_business#171, review_count, review_count#64, average_stars, average_stars#280)) AS features#1103]\n               +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, UDF(cast(compliment_count#251 as string)) AS compliment_count_SI#1081]\n                  +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, UDF(cast(city#58 as string)) AS city_SI#1063]\n                     +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, UDF(cast(state#59 as string)) AS state_SI#1046]\n                        +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, UDF(cast(stars#447 as string)) AS label#1030]\n                           +- Sample 0.8, 1.0, false, 4135539898498538077\n                              +- Sort [business_id#13 ASC NULLS FIRST, user_id#12 ASC NULLS FIRST, stars#447 ASC NULLS FIRST, useful#15 ASC NULLS FIRST, funny#16 ASC NULLS FIRST, cool#17 ASC NULLS FIRST, state#59 ASC NULLS FIRST, city#58 ASC NULLS FIRST, latitude#61 ASC NULLS FIRST, longitude#62 ASC NULLS FIRST, stars_business#171 ASC NULLS FIRST, review_count#64 ASC NULLS FIRST, average_stars#280 ASC NULLS FIRST, compliment_count#251 ASC NULLS FIRST], false\n                                 +- Project [business_id#13, user_id#12, CASE WHEN (stars#14 <= 3) THEN 0 ELSE 1 END AS stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\n                                    +- Filter isnotnull(stars#14)\n                                       +- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\n                                          +- Join LeftOuter, ((business_id#13 = business_id#248) && (user_id#12 = user_id#247))\n                                             :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280]\n                                             :  +- Join LeftOuter, (user_id#12 = user_id#270)\n                                             :     :- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\n                                             :     :  +- Join LeftOuter, (business_id#13 = business_id#55)\n                                             :     :     :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17]\n                                             :     :     :  +- Project [review_id#11, user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, text#18, date#19]\n                                             :     :     :     +- Relation[_c0#10,review_id#11,user_id#12,business_id#13,stars#14,useful#15,funny#16,cool#17,text#18,date#19] csv\n                                             :     :     +- Project [business_id#55, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\n                                             :     :        +- Project [business_id#55, name#56, address#57, city#58, state#59, postal_code#60, latitude#61, longitude#62, stars#63 AS stars_business#171, review_count#64, is_open#65, attributes.GoodForKids#66, attributes.RestaurantsReservations#67, attributes.GoodForMeal#68, attributes.BusinessParking#69, attributes.Caters#70, attributes.NoiseLevel#71, attributes.RestaurantsTableService#72, attributes.RestaurantsTakeOut#73, attributes.RestaurantsPriceRange2#74, attributes.OutdoorSeating#75, attributes.BikeParking#76, attributes.Ambience#77, attributes.HasTV#78, ... 34 more fields]\n                                             :     :           +- Relation[business_id#55,name#56,address#57,city#58,state#59,postal_code#60,latitude#61,longitude#62,stars#63,review_count#64,is_open#65,attributes.GoodForKids#66,attributes.RestaurantsReservations#67,attributes.GoodForMeal#68,attributes.BusinessParking#69,attributes.Caters#70,attributes.NoiseLevel#71,attributes.RestaurantsTableService#72,attributes.RestaurantsTakeOut#73,attributes.RestaurantsPriceRange2#74,attributes.OutdoorSeating#75,attributes.BikeParking#76,attributes.Ambience#77,attributes.HasTV#78,... 34 more fields] csv\n                                             :     +- Project [user_id#270, average_stars#280]\n                                             :        +- Project [user_id#270, name#271, review_count#272 AS review_count_user#383, yelping_since#273, useful_user#314, funny_user#337, cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\n                                             :           +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny_user#337, cool#276 AS cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\n                                             :              +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny#275 AS funny_user#337, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\n                                             :                 +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful#274 AS useful_user#314, funny#275, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\n                                             :                    +- Relation[user_id#270,name#271,review_count#272,yelping_since#273,useful#274,funny#275,cool#276,elite#277,friends#278,fans#279,average_stars#280,compliment_hot#281,compliment_more#282,compliment_profile#283,compliment_cute#284,compliment_list#285,compliment_note#286,compliment_plain#287,compliment_cool#288,compliment_funny#289,compliment_writer#290,compliment_photos#291] csv\n                                             +- Project [user_id#247, business_id#248, compliment_count#251]\n                                                +- Relation[user_id#247,business_id#248,text#249,date#250,compliment_count#251] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3407)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1335)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fbfa012cdad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \"\"\"\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`predictions`' given input columns: [city, business_id, stars, state_SI, features, average_stars, prediction, cool, useful, rawPrediction, user_id, review_count, city_SI, predictedLabel, probability, stars_business, label, compliment_count_SI, state, compliment_count, funny, latitude, longitude];;\\n'Project [label#1030, 'predictions]\\n+- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, prediction#1166, if (isnull(cast(prediction#1166 as double))) null else UDF(cast(prediction#1166 as double)) AS predictedLabel#1211]\\n   +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, probability#1144, UDF(rawPrediction#1123) AS prediction#1166]\\n      +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, rawPrediction#1123, UDF(rawPrediction#1123) AS probability#1144]\\n         +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, features#1103, UDF(features#1103) AS rawPrediction#1123]\\n            +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, compliment_count_SI#1081, UDF(named_struct(state_SI, state_SI#1046, city_SI, city_SI#1063, compliment_count_SI, compliment_count_SI#1081, useful_double_VectorAssembler_6326843d9a00, cast(useful#15 as double), funny_double_VectorAssembler_6326843d9a00, cast(funny#16 as double), cool_double_VectorAssembler_6326843d9a00, cast(cool#17 as double), latitude, latitude#61, longitude, longitude#62, stars_business, stars_business#171, review_count, review_count#64, average_stars, average_stars#280)) AS features#1103]\\n               +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, city_SI#1063, UDF(cast(compliment_count#251 as string)) AS compliment_count_SI#1081]\\n                  +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, state_SI#1046, UDF(cast(city#58 as string)) AS city_SI#1063]\\n                     +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, label#1030, UDF(cast(state#59 as string)) AS state_SI#1046]\\n                        +- Project [business_id#13, user_id#12, stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251, UDF(cast(stars#447 as string)) AS label#1030]\\n                           +- Sample 0.8, 1.0, false, 4135539898498538077\\n                              +- Sort [business_id#13 ASC NULLS FIRST, user_id#12 ASC NULLS FIRST, stars#447 ASC NULLS FIRST, useful#15 ASC NULLS FIRST, funny#16 ASC NULLS FIRST, cool#17 ASC NULLS FIRST, state#59 ASC NULLS FIRST, city#58 ASC NULLS FIRST, latitude#61 ASC NULLS FIRST, longitude#62 ASC NULLS FIRST, stars_business#171 ASC NULLS FIRST, review_count#64 ASC NULLS FIRST, average_stars#280 ASC NULLS FIRST, compliment_count#251 ASC NULLS FIRST], false\\n                                 +- Project [business_id#13, user_id#12, CASE WHEN (stars#14 <= 3) THEN 0 ELSE 1 END AS stars#447, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\\n                                    +- Filter isnotnull(stars#14)\\n                                       +- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280, compliment_count#251]\\n                                          +- Join LeftOuter, ((business_id#13 = business_id#248) && (user_id#12 = user_id#247))\\n                                             :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64, average_stars#280]\\n                                             :  +- Join LeftOuter, (user_id#12 = user_id#270)\\n                                             :     :- Project [business_id#13, user_id#12, stars#14, useful#15, funny#16, cool#17, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\\n                                             :     :  +- Join LeftOuter, (business_id#13 = business_id#55)\\n                                             :     :     :- Project [user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17]\\n                                             :     :     :  +- Project [review_id#11, user_id#12, business_id#13, stars#14, useful#15, funny#16, cool#17, text#18, date#19]\\n                                             :     :     :     +- Relation[_c0#10,review_id#11,user_id#12,business_id#13,stars#14,useful#15,funny#16,cool#17,text#18,date#19] csv\\n                                             :     :     +- Project [business_id#55, state#59, city#58, latitude#61, longitude#62, stars_business#171, review_count#64]\\n                                             :     :        +- Project [business_id#55, name#56, address#57, city#58, state#59, postal_code#60, latitude#61, longitude#62, stars#63 AS stars_business#171, review_count#64, is_open#65, attributes.GoodForKids#66, attributes.RestaurantsReservations#67, attributes.GoodForMeal#68, attributes.BusinessParking#69, attributes.Caters#70, attributes.NoiseLevel#71, attributes.RestaurantsTableService#72, attributes.RestaurantsTakeOut#73, attributes.RestaurantsPriceRange2#74, attributes.OutdoorSeating#75, attributes.BikeParking#76, attributes.Ambience#77, attributes.HasTV#78, ... 34 more fields]\\n                                             :     :           +- Relation[business_id#55,name#56,address#57,city#58,state#59,postal_code#60,latitude#61,longitude#62,stars#63,review_count#64,is_open#65,attributes.GoodForKids#66,attributes.RestaurantsReservations#67,attributes.GoodForMeal#68,attributes.BusinessParking#69,attributes.Caters#70,attributes.NoiseLevel#71,attributes.RestaurantsTableService#72,attributes.RestaurantsTakeOut#73,attributes.RestaurantsPriceRange2#74,attributes.OutdoorSeating#75,attributes.BikeParking#76,attributes.Ambience#77,attributes.HasTV#78,... 34 more fields] csv\\n                                             :     +- Project [user_id#270, average_stars#280]\\n                                             :        +- Project [user_id#270, name#271, review_count#272 AS review_count_user#383, yelping_since#273, useful_user#314, funny_user#337, cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :           +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny_user#337, cool#276 AS cool_user#360, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :              +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful_user#314, funny#275 AS funny_user#337, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :                 +- Project [user_id#270, name#271, review_count#272, yelping_since#273, useful#274 AS useful_user#314, funny#275, cool#276, elite#277, friends#278, fans#279, average_stars#280, compliment_hot#281, compliment_more#282, compliment_profile#283, compliment_cute#284, compliment_list#285, compliment_note#286, compliment_plain#287, compliment_cool#288, compliment_funny#289, compliment_writer#290, compliment_photos#291]\\n                                             :                    +- Relation[user_id#270,name#271,review_count#272,yelping_since#273,useful#274,funny#275,cool#276,elite#277,friends#278,fans#279,average_stars#280,compliment_hot#281,compliment_more#282,compliment_profile#283,compliment_cute#284,compliment_list#285,compliment_note#286,compliment_plain#287,compliment_cool#288,compliment_funny#289,compliment_writer#290,compliment_photos#291] csv\\n                                             +- Project [user_id#247, business_id#248, compliment_count#251]\\n                                                +- Relation[user_id#247,business_id#248,text#249,date#250,compliment_count#251] csv\\n\""
     ]
    }
   ],
   "source": [
    "predictions.select(\"label\",\"predictions\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
